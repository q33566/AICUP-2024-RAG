{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:20:36.867300Z",
     "start_time": "2024-11-07T17:20:32.145906Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q33566/AI CUP/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.Evaluation import *\n",
    "from utils.Loader import *\n",
    "from utils.Retriever import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from FlagEmbedding import LightWeightFlagLLMReranker\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93469a3",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa7d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file where you want to store the dataset\n",
    "Config.faq_path = Path('../data/reference/faq/pid_map_content.json')\n",
    "Config.finance_path = Path('../data/reference/finance')\n",
    "Config.insurance_path = Path('../data/reference/insurance')\n",
    "# Specify the file where you want to store the ground truth file\n",
    "Config.truth_path = Path('../data/dataset/preliminary/ground_truths_example.json')\n",
    "# Specify the file where you want to store the baseline prediction file\n",
    "Config.prediction_path = Path('../data/dataset/preliminary/pred_retrieve.json')\n",
    "# Specify the file where you want to store the own method(in here we use hybrid retrieve + reranker) prediction file\n",
    "Config.my_prediction_path = Path('../data/dataset/my_ans/pred_retrieve.json')\n",
    "# Specify the file where you want to store the question file\n",
    "Config.queries_info_path = Path('../data/dataset/preliminary/questions_example.json')\n",
    "# Specify the directory where you want to store the embedding model and reranker model\n",
    "Config.model_cache = Path('/HDD/model_cache/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bdbe8b",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Prepare two types of datasets: one for BM25 (chunk size = 1 page of the PDF) and another for vector embedding (chunk size = 512 tokens). Additionally, we separate the datasets by their category (e.g., insurance, finance, FAQ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36912aea96c64a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:38:56.195047Z",
     "start_time": "2024-11-07T17:37:20.333640Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 643/643 [00:02<00:00, 291.48it/s]\n",
      "Loading data: 100%|██████████| 1035/1035 [00:19<00:00, 51.86it/s]\n",
      "Loading data: 100%|██████████| 617/617 [00:00<00:00, 566276.93it/s]\n",
      "Loading data: 100%|██████████| 643/643 [00:02<00:00, 293.36it/s]\n",
      "Loading data: 100%|██████████| 1035/1035 [00:20<00:00, 50.23it/s]\n",
      "Loading data: 100%|██████████| 617/617 [00:00<00:00, 512655.62it/s]\n"
     ]
    }
   ],
   "source": [
    "bm25_insurance_corpus_df = load_data(source_path=Config.insurance_path, is_chunking=False)\n",
    "bm25_finance_corpus_df = load_data(source_path=Config.finance_path, is_chunking=False)\n",
    "bm25_faq_corpus_df = load_faq(Config.faq_path)\n",
    "\n",
    "vector_insurance_corpus_df = load_data(source_path=Config.insurance_path, is_chunking=True)\n",
    "vector_finance_corpus_df = load_data(source_path=Config.finance_path, is_chunking=True)\n",
    "vector_faq_corpus_df = load_faq(Config.faq_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778fc05",
   "metadata": {},
   "source": [
    "Load queries for three category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5223f6a59d49a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:38:58.273991Z",
     "start_time": "2024-11-07T17:38:58.138654Z"
    }
   },
   "outputs": [],
   "source": [
    "# Config.queries_info_path: 訓練資料集query\n",
    "# Config.formal_queries_info_path: 正式比賽query\n",
    "queries_info_df = get_queried_info(Config.queries_info_path) # 正式比賽query: Config.queries_info_path\n",
    "insurance_queries_info_df = queries_info_df[queries_info_df['category'] == 'insurance']\n",
    "finance_queries_info_df = queries_info_df[queries_info_df['category'] == 'finance']\n",
    "faq_queries_info_df = queries_info_df[queries_info_df['category'] == 'faq']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f9b2b",
   "metadata": {},
   "source": [
    "Load the intfloat/multilingual-e5-large dense vector embedding model for hybrid retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab9678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"intfloat/multilingual-e5-large\", cache_folder='/HDD/model_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debfc6b3",
   "metadata": {},
   "source": [
    "Calculate the BM25 and embedding vector scores, along with the rankings, for the dataset with respect to each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08cca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.423 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.54it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.08it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 171.05it/s]\n",
      "100%|██████████| 50/50 [00:30<00:00,  1.65it/s]\n",
      "100%|██████████| 50/50 [00:45<00:00,  1.09it/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  8.23it/s]\n"
     ]
    }
   ],
   "source": [
    "insurance_bm25_retrieve: pd.DataFrame = BM25Retrieve.retrieve(queries_info=insurance_queries_info_df, \n",
    "                                                corpus_df = bm25_insurance_corpus_df)\n",
    "finance_bm25_retrieve: pd.DataFrame = BM25Retrieve.retrieve(queries_info=finance_queries_info_df, \n",
    "                                                corpus_df = bm25_finance_corpus_df)\n",
    "faq_bm25_retrieve: pd.DataFrame = BM25Retrieve.retrieve(queries_info=faq_queries_info_df,\n",
    "                                                     corpus_df = bm25_faq_corpus_df)\n",
    "insurance_vector_retrieve: pd.DataFrame = VectorRetriever.retrieve(embedder, queries_info=insurance_queries_info_df,\n",
    "                                                     corpus_df = vector_insurance_corpus_df)\n",
    "finance_vector_retrieve: pd.DataFrame = VectorRetriever.retrieve(embedder, queries_info=finance_queries_info_df,\n",
    "                                                     corpus_df = vector_finance_corpus_df)\n",
    "faq_vector_retrieve: pd.DataFrame = VectorRetriever.retrieve(embedder, queries_info=faq_queries_info_df,\n",
    "                                                     corpus_df = vector_faq_corpus_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7319bb5",
   "metadata": {},
   "source": [
    "Perform hybrid retrieval using RRF (refer to README.md for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce3a866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_hybrid_retrieve_pd: pd.DataFrame = get_hybrid_retrieve_pd(bm25_retrieve_pd = insurance_bm25_retrieve, \n",
    "                                            vector_retrieve_pd = insurance_vector_retrieve)\n",
    "finance_hybrid_retrieve_pd: pd.DataFrame = get_hybrid_retrieve_pd(bm25_retrieve_pd = finance_bm25_retrieve, \n",
    "                                            vector_retrieve_pd = finance_vector_retrieve)\n",
    "faq_hybrid_retrieve_pd: pd.DataFrame = get_hybrid_retrieve_pd(bm25_retrieve_pd = faq_bm25_retrieve, \n",
    "                                            vector_retrieve_pd = faq_vector_retrieve)\n",
    "\n",
    "insurance_hybrid_rrf_retrieve_pd: pd.DataFrame = get_RRF_score(insurance_hybrid_retrieve_pd)\n",
    "finance_hybrid_rrf_retrieve_pd: pd.DataFrame = get_RRF_score(finance_hybrid_retrieve_pd)\n",
    "faq_hybrid_rrf_retrieve_pd: pd.DataFrame = get_RRF_score(faq_hybrid_retrieve_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708319d7",
   "metadata": {},
   "source": [
    "Load the reranker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "797edd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.29it/s]\n"
     ]
    }
   ],
   "source": [
    "reranker1 = LightWeightFlagLLMReranker(\n",
    "    'BAAI/bge-reranker-v2.5-gemma2-lightweight', \n",
    "    query_max_length=256,\n",
    "    passage_max_length=512,\n",
    "    use_fp16=True,\n",
    "    devices=['cuda:1'],\n",
    "    cache_dir = Config.model_cache\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3877b",
   "metadata": {},
   "source": [
    "Pair up the queries with their corresponding retrieved sentences, then apply a reranker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81741941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|██████████| 3/3 [00:00<00:00, 114.11it/s]\n",
      "You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 3/3 [00:15<00:00,  5.10s/it]\n",
      "pre tokenize: 100%|██████████| 3/3 [00:00<00:00, 93.45it/s]\n",
      "100%|██████████| 3/3 [00:19<00:00,  6.64s/it]\n",
      "pre tokenize: 100%|██████████| 6/6 [00:00<00:00, 190.15it/s]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "reranked_insurance_retrieve = apply_reranking(reranker=reranker1, hybrid_retrieve=insurance_hybrid_rrf_retrieve_pd)\n",
    "reranked_finance_retrieve = apply_reranking(reranker=reranker1, hybrid_retrieve=finance_hybrid_rrf_retrieve_pd)\n",
    "reranked_faq_retrieve = apply_reranking(reranker=reranker1 , hybrid_retrieve=faq_hybrid_rrf_retrieve_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9408934",
   "metadata": {},
   "source": [
    "Obtain the final retrieved answers based on the re-ranking scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "931c6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_top_1_retrieve_df = get_top_1_retrieve_pd(reranked_insurance_retrieve, score_field='reranking_score')\n",
    "finance_top_1_retrieve_df = get_top_1_retrieve_pd(reranked_finance_retrieve, score_field='reranking_score')\n",
    "faq_top_1_retrieve_df = get_top_1_retrieve_pd(reranked_faq_retrieve, score_field='reranking_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca768d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': [{'qid': 1, 'retrieve': 392},\n",
       "  {'qid': 2, 'retrieve': 606},\n",
       "  {'qid': 3, 'retrieve': 83},\n",
       "  {'qid': 4, 'retrieve': 186},\n",
       "  {'qid': 5, 'retrieve': 162},\n",
       "  {'qid': 6, 'retrieve': 116},\n",
       "  {'qid': 7, 'retrieve': 107},\n",
       "  {'qid': 8, 'retrieve': 78},\n",
       "  {'qid': 9, 'retrieve': 62},\n",
       "  {'qid': 10, 'retrieve': 472},\n",
       "  {'qid': 11, 'retrieve': 7},\n",
       "  {'qid': 12, 'retrieve': 526},\n",
       "  {'qid': 13, 'retrieve': 526},\n",
       "  {'qid': 14, 'retrieve': 526},\n",
       "  {'qid': 15, 'retrieve': 536},\n",
       "  {'qid': 16, 'retrieve': 54},\n",
       "  {'qid': 17, 'retrieve': 606},\n",
       "  {'qid': 18, 'retrieve': 184},\n",
       "  {'qid': 19, 'retrieve': 315},\n",
       "  {'qid': 20, 'retrieve': 292},\n",
       "  {'qid': 21, 'retrieve': 36},\n",
       "  {'qid': 22, 'retrieve': 614},\n",
       "  {'qid': 23, 'retrieve': 99},\n",
       "  {'qid': 24, 'retrieve': 359},\n",
       "  {'qid': 25, 'retrieve': 4},\n",
       "  {'qid': 26, 'retrieve': 147},\n",
       "  {'qid': 27, 'retrieve': 171},\n",
       "  {'qid': 28, 'retrieve': 298},\n",
       "  {'qid': 29, 'retrieve': 524},\n",
       "  {'qid': 30, 'retrieve': 327},\n",
       "  {'qid': 31, 'retrieve': 10},\n",
       "  {'qid': 32, 'retrieve': 51},\n",
       "  {'qid': 33, 'retrieve': 434},\n",
       "  {'qid': 34, 'retrieve': 442},\n",
       "  {'qid': 35, 'retrieve': 224},\n",
       "  {'qid': 36, 'retrieve': 148},\n",
       "  {'qid': 37, 'retrieve': 148},\n",
       "  {'qid': 38, 'retrieve': 353},\n",
       "  {'qid': 39, 'retrieve': 29},\n",
       "  {'qid': 40, 'retrieve': 578},\n",
       "  {'qid': 41, 'retrieve': 165},\n",
       "  {'qid': 42, 'retrieve': 325},\n",
       "  {'qid': 43, 'retrieve': 325},\n",
       "  {'qid': 44, 'retrieve': 440},\n",
       "  {'qid': 45, 'retrieve': 537},\n",
       "  {'qid': 46, 'retrieve': 66},\n",
       "  {'qid': 47, 'retrieve': 620},\n",
       "  {'qid': 48, 'retrieve': 8},\n",
       "  {'qid': 49, 'retrieve': 37},\n",
       "  {'qid': 50, 'retrieve': 555},\n",
       "  {'qid': 51, 'retrieve': 162},\n",
       "  {'qid': 52, 'retrieve': 918},\n",
       "  {'qid': 53, 'retrieve': 351},\n",
       "  {'qid': 54, 'retrieve': 612},\n",
       "  {'qid': 55, 'retrieve': 166},\n",
       "  {'qid': 56, 'retrieve': 171},\n",
       "  {'qid': 57, 'retrieve': 668},\n",
       "  {'qid': 58, 'retrieve': 209},\n",
       "  {'qid': 59, 'retrieve': 632},\n",
       "  {'qid': 60, 'retrieve': 726},\n",
       "  {'qid': 61, 'retrieve': 951},\n",
       "  {'qid': 62, 'retrieve': 591},\n",
       "  {'qid': 63, 'retrieve': 306},\n",
       "  {'qid': 64, 'retrieve': 124},\n",
       "  {'qid': 65, 'retrieve': 255},\n",
       "  {'qid': 66, 'retrieve': 192},\n",
       "  {'qid': 67, 'retrieve': 1021},\n",
       "  {'qid': 68, 'retrieve': 942},\n",
       "  {'qid': 69, 'retrieve': 978},\n",
       "  {'qid': 70, 'retrieve': 272},\n",
       "  {'qid': 71, 'retrieve': 920},\n",
       "  {'qid': 72, 'retrieve': 204},\n",
       "  {'qid': 73, 'retrieve': 235},\n",
       "  {'qid': 74, 'retrieve': 569},\n",
       "  {'qid': 75, 'retrieve': 71},\n",
       "  {'qid': 76, 'retrieve': 211},\n",
       "  {'qid': 77, 'retrieve': 843},\n",
       "  {'qid': 78, 'retrieve': 119},\n",
       "  {'qid': 79, 'retrieve': 550},\n",
       "  {'qid': 80, 'retrieve': 837},\n",
       "  {'qid': 81, 'retrieve': 671},\n",
       "  {'qid': 82, 'retrieve': 679},\n",
       "  {'qid': 83, 'retrieve': 155},\n",
       "  {'qid': 84, 'retrieve': 745},\n",
       "  {'qid': 85, 'retrieve': 891},\n",
       "  {'qid': 86, 'retrieve': 189},\n",
       "  {'qid': 87, 'retrieve': 701},\n",
       "  {'qid': 88, 'retrieve': 256},\n",
       "  {'qid': 89, 'retrieve': 793},\n",
       "  {'qid': 90, 'retrieve': 710},\n",
       "  {'qid': 91, 'retrieve': 22},\n",
       "  {'qid': 92, 'retrieve': 55},\n",
       "  {'qid': 93, 'retrieve': 660},\n",
       "  {'qid': 94, 'retrieve': 350},\n",
       "  {'qid': 95, 'retrieve': 307},\n",
       "  {'qid': 96, 'retrieve': 435},\n",
       "  {'qid': 97, 'retrieve': 282},\n",
       "  {'qid': 98, 'retrieve': 692},\n",
       "  {'qid': 99, 'retrieve': 693},\n",
       "  {'qid': 100, 'retrieve': 273},\n",
       "  {'qid': 101, 'retrieve': 558},\n",
       "  {'qid': 102, 'retrieve': 104},\n",
       "  {'qid': 103, 'retrieve': 63},\n",
       "  {'qid': 104, 'retrieve': 15},\n",
       "  {'qid': 105, 'retrieve': 294},\n",
       "  {'qid': 106, 'retrieve': 224},\n",
       "  {'qid': 107, 'retrieve': 540},\n",
       "  {'qid': 108, 'retrieve': 105},\n",
       "  {'qid': 109, 'retrieve': 282},\n",
       "  {'qid': 110, 'retrieve': 611},\n",
       "  {'qid': 111, 'retrieve': 76},\n",
       "  {'qid': 112, 'retrieve': 403},\n",
       "  {'qid': 113, 'retrieve': 509},\n",
       "  {'qid': 114, 'retrieve': 279},\n",
       "  {'qid': 115, 'retrieve': 54},\n",
       "  {'qid': 116, 'retrieve': 4},\n",
       "  {'qid': 117, 'retrieve': 92},\n",
       "  {'qid': 118, 'retrieve': 554},\n",
       "  {'qid': 119, 'retrieve': 610},\n",
       "  {'qid': 120, 'retrieve': 20},\n",
       "  {'qid': 121, 'retrieve': 414},\n",
       "  {'qid': 122, 'retrieve': 415},\n",
       "  {'qid': 123, 'retrieve': 527},\n",
       "  {'qid': 124, 'retrieve': 14},\n",
       "  {'qid': 125, 'retrieve': 604},\n",
       "  {'qid': 126, 'retrieve': 1},\n",
       "  {'qid': 127, 'retrieve': 365},\n",
       "  {'qid': 128, 'retrieve': 436},\n",
       "  {'qid': 129, 'retrieve': 283},\n",
       "  {'qid': 130, 'retrieve': 5},\n",
       "  {'qid': 131, 'retrieve': 600},\n",
       "  {'qid': 132, 'retrieve': 334},\n",
       "  {'qid': 133, 'retrieve': 243},\n",
       "  {'qid': 134, 'retrieve': 328},\n",
       "  {'qid': 135, 'retrieve': 399},\n",
       "  {'qid': 136, 'retrieve': 504},\n",
       "  {'qid': 137, 'retrieve': 359},\n",
       "  {'qid': 138, 'retrieve': 339},\n",
       "  {'qid': 139, 'retrieve': 194},\n",
       "  {'qid': 140, 'retrieve': 141},\n",
       "  {'qid': 141, 'retrieve': 410},\n",
       "  {'qid': 142, 'retrieve': 173},\n",
       "  {'qid': 143, 'retrieve': 144},\n",
       "  {'qid': 144, 'retrieve': 225},\n",
       "  {'qid': 145, 'retrieve': 564},\n",
       "  {'qid': 146, 'retrieve': 0},\n",
       "  {'qid': 147, 'retrieve': 87},\n",
       "  {'qid': 148, 'retrieve': 242},\n",
       "  {'qid': 149, 'retrieve': 441},\n",
       "  {'qid': 150, 'retrieve': 221}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer_json([insurance_top_1_retrieve_df, finance_top_1_retrieve_df, faq_top_1_retrieve_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3785e71",
   "metadata": {},
   "source": [
    "Evaluate the performance of hybrid retrieval combined with re-ranking on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78d7436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insurance: 0.8400\n",
      "finance: 0.8400\n",
      "faq: 0.9600\n",
      "total: 0.88\n"
     ]
    }
   ],
   "source": [
    "#result\n",
    "evaluation(Config.my_prediction_path, Config.truth_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45fac4",
   "metadata": {},
   "source": [
    "Evaluate the performance of baseline code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff81e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insurance: 0.8000\n",
      "finance: 0.4400\n",
      "faq: 0.9000\n",
      "total: 0.7133333333333334\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "evaluation(Config.prediction_path, Config.truth_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
